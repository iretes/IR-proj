{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Large Scale Experiments\n",
    "\n",
    "Importing libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from search_approaches import IVF\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining constants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "DATASET = \"sift\"\n",
    "DIR = \"sift\"\n",
    "SEARCH_TRAIN_SUBSET = False\n",
    "tab20 = matplotlib.colormaps[\"tab20\"]\n",
    "tab20c = matplotlib.colormaps[\"tab20c\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_data, search_data, queries, gt = load_data(\n",
    "    dataset_name=DATASET,\n",
    "    dataset_dir=DIR,\n",
    "    search_train_subset=SEARCH_TRAIN_SUBSET,\n",
    "    random_seed=RANDOM_SEED\n",
    ")\n",
    "\n",
    "sample_query = queries[0]\n",
    "sample_query_snorm = np.sum(np.square(sample_query))\n",
    "print(\"Base vectors (to search in) shape: \", search_data.shape)\n",
    "print(f\"Base vectors (to search in) range: [{search_data.min()}, {search_data.max()}]\")\n",
    "print(\"Query vectors shape: \", queries.shape)\n",
    "print(\"Ground truth shape: \", gt.shape)\n",
    "print(\"Learn vectors shape: \", tr_data.shape)\n",
    "print(\"Query example:\\n\", queries[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a function to compute the average recall at various values of R for a set of queries. Both the \"nearest recall at R\" and \"recall at R\" are computed: the former measures the proportion of query vectors for which the nearest neighbor is ranked in the first R positions, while the latter measures the average recall at R. In the original article, only \"nearest recall at R is analyzed, with the authors noting that the conclusions are similar for recall at R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_recall(index, exact_ranks, R, queries, w):\n",
    "    \"\"\"\n",
    "    Compute average recall at all values in R for the given index and queries.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    index : PQ or IVF\n",
    "        The index to use for the search.\n",
    "\n",
    "    exact_ranks : np.ndarray\n",
    "        The exact ranking of the search data for each query.\n",
    "\n",
    "    R : list\n",
    "        The list of values for which to compute the recall at.\n",
    "\n",
    "    queries : np.ndarray\n",
    "        The queries to use for the search.\n",
    "\n",
    "    w : int\n",
    "        The number of centroids to visit in the IVF index.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    results : dict\n",
    "        A dictionary containing the mean recall at each value of R for the\n",
    "        asymmetric distance computation.\n",
    "        Recall is computed both as the number of relevant items in the top R,\n",
    "        and as the presence of the nearest item in the top R (nearest recall).\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    for r in R:\n",
    "        if r > exact_ranks.shape[1]:\n",
    "            raise ValueError(f\"r={r} is greater than the number of ground truth neighbors\")\n",
    "    \n",
    "    asym_recall = np.full((len(queries), len(R)), np.nan)\n",
    "    nearest_asym_recall = np.full((len(queries), len(R)), np.nan)\n",
    "    for i, query in enumerate(queries):\n",
    "        _, asym_rank = index.search(query, w=w, asym=True, correct=False)\n",
    "        for j, r in enumerate(R):\n",
    "            if r <= len(asym_rank):\n",
    "                asym_recall[i][j] = recall_at_r(asym_rank, exact_ranks[i], r)\n",
    "                nearest_asym_recall[i][j] = exact_ranks[i][0] in asym_rank[:r]\n",
    "\n",
    "    with warnings.catch_warnings(record=True) as w:\n",
    "        asym_recall_mean = np.nanmean(asym_recall, axis=0)\n",
    "        nearest_asym_recall_mean = np.nanmean(nearest_asym_recall, axis=0)\n",
    "        if w:\n",
    "            for warning in w:\n",
    "                if \"Mean of empty slice\" not in str(warning.message):\n",
    "                    warnings.warn(warning.message, warning.category)\n",
    "    \n",
    "    return {\n",
    "        \"asym_recall_mean\": asym_recall_mean,\n",
    "        \"nearest_asym_recall_mean\": nearest_asym_recall_mean\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the search performance and training time when using KMeans, MiniBatch Kmeans (with default parameters, i.e. `batch_size=1024`) and Bisecting KMeans for the coarse clustering. This is implemented by calling the IVF constructor and specifying the parameter `coarse_clust_alg`. Recall is evaluated only at 1 at maximum of 100 because the ground truth rankings provided by the dataset authors are limited to the top 100 nearest neighbors, and computing the full ranking would be computationally expensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 256\n",
    "M = 8\n",
    "KPs = [1024, 8192]\n",
    "Ws = [8, 64]\n",
    "R = [1, 2, 5, 10, 25, 50, 100]\n",
    "\n",
    "results = []\n",
    "for i, kp in enumerate(KPs):\n",
    "    for clust_alg in [\"km\", \"mkm\", \"bkm\"]:\n",
    "        ivf = IVF(Kp=kp, M=M, K=K, seed=RANDOM_SEED, coarse_clust_alg=clust_alg)\n",
    "        print(f\"Training IVFADC with k'={kp}, w={Ws[i]}, coarse_clust_alg={clust_alg}...\")\n",
    "        start_training = time.time()\n",
    "        ivf.train(tr_data, add=False)\n",
    "        training_time = time.time() - start_training\n",
    "        print(\"Adding search data to IVFADC...\")\n",
    "        ivf.add(search_data, compute_distortions=True)\n",
    "        print(\"Computing recall...\")\n",
    "        res = compute_recall(ivf, gt, R, queries, w=Ws[i])\n",
    "        results.append({\n",
    "            \"k'\" : kp,\n",
    "            \"coarse_clust_alg\": clust_alg,\n",
    "            \"training_time\": training_time,\n",
    "            **res\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "colors = [\"black\", \"orange\", \"red\", \"gray\", \"cornflowerblue\", \"blue\"]\n",
    "markers = [\"--s\", \"-o\", \"-x\", \"-.d\", \"-v\", \"-P\"]\n",
    "for i, res in enumerate(results):\n",
    "    kp = res[\"k'\"]\n",
    "    w = Ws[KPs.index(kp)]\n",
    "    if res[\"coarse_clust_alg\"] == \"km\":\n",
    "        coarse_clust_alg = \"KMeans\"\n",
    "    elif res[\"coarse_clust_alg\"] == \"bkm\":\n",
    "        coarse_clust_alg = \"Bisecting KMeans\"\n",
    "    else:\n",
    "        coarse_clust_alg = \"MiniBatch KMeans\"\n",
    "    mean_recall = np.nanmean(res['asym_recall_mean'])\n",
    "    label = f\"k'={kp}, w={w}, {coarse_clust_alg} ({mean_recall:.2f})\"\n",
    "    axs[0].plot(R, res[\"nearest_asym_recall_mean\"], markers[i], label=label, color=colors[i])\n",
    "\n",
    "axs[0].set_xscale('log')\n",
    "axs[0].set_xlabel('R')\n",
    "axs[0].set_ylabel('Nearest recall@R')\n",
    "axs[0].legend(title=\"Method (Mean nearest recall@R)\")\n",
    "axs[0].grid()\n",
    "\n",
    "times_df = pd.DataFrame({\n",
    "    \"k'\": KPs,\n",
    "    \"Training time KMeans\": [res[\"training_time\"] for res in results if res[\"coarse_clust_alg\"]==\"km\"],\n",
    "    \"Training time MiniBatch KMeans\": [res[\"training_time\"] for res in results if res[\"coarse_clust_alg\"]==\"mkm\"],\n",
    "    \"Training time Bisecting KMeans\": [res[\"training_time\"] for res in results if res[\"coarse_clust_alg\"]==\"bkm\"]\n",
    "    })\n",
    "times_df.set_index(\"k'\", inplace=True)\n",
    "ax = times_df.plot.bar(rot=0, ax=axs[1], legend=False)\n",
    "for i, bar in enumerate(ax.patches):\n",
    "    if i%2==0:\n",
    "        bar.set_color(colors[:3][i//2])\n",
    "    else:\n",
    "        bar.set_color(colors[3:][i//2])\n",
    "legend_patches = []\n",
    "for i, res in enumerate(results):\n",
    "    kp = res[\"k'\"]\n",
    "    w = Ws[KPs.index(kp)]\n",
    "    if res[\"coarse_clust_alg\"] == \"km\":\n",
    "        coarse_clust_alg = \"KMeans\"\n",
    "    elif res[\"coarse_clust_alg\"] == \"bkm\":\n",
    "        coarse_clust_alg = \"Bisecting KMeans\"\n",
    "    else:\n",
    "        coarse_clust_alg = \"MiniBatch KMeans\"\n",
    "    label = f\"w={w}, {coarse_clust_alg}\"\n",
    "    legend_patches.append(mpatches.Patch(color=colors[i], label=label))\n",
    "ax.legend(handles=legend_patches, title=\"Method\")\n",
    "ax.set_ylabel(\"Training time [s]\");\n",
    "\n",
    "fig.suptitle(f\"IVFADC, m={M}, k*={K}\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
